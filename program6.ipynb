{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e8c2888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total instance available : 766\n",
      "total attribute present ; 7\n",
      "1st five values are:\n",
      "1 : [1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0]\n",
      "2 : [8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0]\n",
      "3 : [1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0]\n",
      "4 : [0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0]\n",
      "5 : [5.0, 116.0, 74.0, 0.0, 0.0, 25.6, 0.201, 30.0]\n",
      "training examples=574 \n",
      " testing examples=192\n",
      "accuracy of naive bayes classifier is : 75.52083333333334\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import statistics as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "def summarizeByClass(x_tr,y_tr):\n",
    "    separated={}\n",
    "    for i in range(len(x_train)):\n",
    "        x,y=x_tr[i],y_tr[i]\n",
    "        if y not in separated:\n",
    "            separated[y]=[]\n",
    "        separated[y].append(x)\n",
    "    summary={}\n",
    "    for lbl,subset in separated.items():\n",
    "        summary[lbl]=[(st.mean(attribute),st.stdev(attribute)) for attribute in zip(*subset)]\n",
    "    return summary\n",
    "def estimateProbability(x,mean,stdev):\n",
    "    estimate=math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1/(math.sqrt(2*math.pi)*stdev))*estimate\n",
    "def predict(summaries,testvector):\n",
    "    bestLabel,bestprob=None ,-1\n",
    "    p={}\n",
    "    for lbl,mean_std in summaries.items():\n",
    "        p[lbl]=1\n",
    "        for i in range(len(mean_std)):\n",
    "            mean,stdev=mean_std[i]\n",
    "            x=testvector[i]\n",
    "            p[lbl]*=estimateProbability(x,mean,stdev) \n",
    "        if bestLabel == None or p[lbl]>bestprob:\n",
    "            bestprob=p[lbl]\n",
    "            bestLabel=lbl\n",
    "    return bestLabel\n",
    "def do_classification_compute_accuracy(summaries,test_x,test_y):\n",
    "    correct=0\n",
    "    for i in range(len(test_x)):\n",
    "        result=predict(summaries,test_x[i])\n",
    "        if result==test_y[i]:\n",
    "            correct=correct+1\n",
    "    accuracy=(correct/(float(len(test_x))))*100.0\n",
    "    return accuracy\n",
    "df=pd.read_csv('prgm6.csv')\n",
    "col=[0,1,2,3,4,5,6,7]\n",
    "df_x=df[df.columns[col]]\n",
    "df_y=df[df.columns[8]]\n",
    "x=df_x.values.tolist()\n",
    "y=df_y.values.tolist()\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y)\n",
    "print('total instance available :',len(x))\n",
    "print('total attribute present ;',len(x[0])-1)\n",
    "print('1st five values are:')\n",
    "for i in range(5):\n",
    "    print(i+1 ,':' ,x[i])\n",
    "print('training examples={0} \\n testing examples={1}'.format(len(x_train),len(x_test)))\n",
    "summaries=summarizeByClass(x_train,y_train)\n",
    "accuracy=do_classification_compute_accuracy(summaries,x_test,y_test)\n",
    "print('accuracy of naive bayes classifier is :',accuracy)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a6d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e230abd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
